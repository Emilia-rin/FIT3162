{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import os, sys, glob, csv, keras\n",
    "from sklearn import model_selection, preprocessing\n",
    "from os import walk, path\n",
    "from keras import models, layers, optimizers, preprocessing as KRSpreps, utils as KRSutils\n",
    "#from tslearn import preprocessing as TSpreps, utils as TSutils\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Flatten, Dropout, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow import keras\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from glob import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary and store paths for all different Modalities(Micro-expression and Gaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = {}\n",
    "data_path['gazedata_path'] = \"Gaze_Features/\"\n",
    "data_path['mexpdata_path'] = \"Mexp_Features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/jingweiong/Downloads/Deception-Detection-master\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking No. of files in each of Micro-expression & Gaze Folders && Shape of the Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/Users/jingweiong/Downloads/Deception_detection_output_mexp_gaze\"\n",
    "data_shape_all = pd.DataFrame()\n",
    "\n",
    "for key in data_path.keys():\n",
    "    count = 0\n",
    "    data_shape, file_names = [], []\n",
    "    for filepath in glob(path.join(dir, '*.csv')):\n",
    "        file_shape = pd.read_csv(filepath).shape\n",
    "        filename = path.basename(filepath)\n",
    "        for reps in ((\"Mexp_\", \"\"), (\"Gaze_\", \"\")):\n",
    "            filename = filename.replace(*reps)       \n",
    "        if filename not in ['Annotation_mexp_features.csv', 'Annotation_gaze_features.csv']:\n",
    "            data_shape.append([file_shape[0], file_shape[1]])\n",
    "            file_names.append(filename)\n",
    "            count+=1\n",
    "    data_shape = pd.DataFrame(data_shape)\n",
    "    data_shape.columns = [key + str(0), key + str(1)]\n",
    "    data_shape.index = pd.Series(file_names)\n",
    "    \n",
    "    # Ensure index values are unique before concatenating\n",
    "    data_shape = data_shape[~data_shape.index.duplicated(keep='first')]\n",
    "    \n",
    "    data_shape_all = pd.concat([data_shape_all, data_shape], axis=1, sort=True)\n",
    "    print(f\"No. of file in {key}: \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dictionaries of Micro-expression & Gaze\n",
    "Remove Initials and Make the Keys Same for the Same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_dict, mexp_dict = {}, {}\n",
    "listofdicts = [gaze_dict, mexp_dict]\n",
    "for key, data_dict_indiv in zip(data_path.keys(), listofdicts):\n",
    "    for filepath in glob(path.join(dir, '*.csv')):\n",
    "        data = pd.read_csv(filepath)\n",
    "        filename = path.basename(filepath)\n",
    "        for reps in ((\"Gaze_\", \"\"), (\"Mexp_\", \"\")):\n",
    "            filename = filename.replace(*reps)\n",
    "        data_dict_indiv[filename] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking If the Labels are Same for Same Keys in Each Dcitionaries & Separating Labels from Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dictkeys = list(gaze_dict)\n",
    "label_dict = {}\n",
    "for key in filename_dictkeys:\n",
    "    # print(key)\n",
    "    gazedata, mexpdata = gaze_dict[key], mexp_dict[key]\n",
    "    label_gaze = gazedata.loc[:, \"label\"].unique()[0]\n",
    "    label_mexp = mexpdata.loc[:, \"label\"].unique()[0]\n",
    "    label_set = set([label_gaze, label_mexp])\n",
    "    if len(label_set) > 1:\n",
    "        print(key)\n",
    "    else:\n",
    "        label_dict[key] = list(label_set)[0]\n",
    "print(\"No. of files with same label: \", len(label_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Indexing Columns & Labels from Training Data && Reindexing with TIme && Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "filename_dictkeys = list(gaze_dict)\n",
    "gaze_dict_upsampled, mexp_dict_upsampled = {}, {}\n",
    "for key in filename_dictkeys:\n",
    "    gaze_data = np.array(gaze_dict[key].drop([\"frame\", \"Unnamed: 0\", \"label\", \"face_id\", \"timestamp\", \"confidence\", \"success\"], axis = 1).drop_duplicates())\n",
    "    gaze_dict_upsampled[key] = resample(gaze_data, 300)\n",
    "    mexp_data = np.array(mexp_dict[key].drop([\"frame\", \"Unnamed: 0\", \"label\", \"face_id\", \"timestamp\", \"confidence\", \"success\"], axis = 1).drop_duplicates())\n",
    "    mexp_dict_upsampled[key] = resample(mexp_data, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Gaze and Microexpression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = {}\n",
    "for key in gaze_dict_upsampled:\n",
    "    combined_features = np.hstack([gaze_dict_upsampled[key], mexp_dict_upsampled[key]])\n",
    "    combined_data[key] = combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_columns = max(data.shape[1] for data in combined_data.values())\n",
    "print(\"Maximum columns required:\", max_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "adjusted_combined_data = {}\n",
    "\n",
    "for key, data in combined_data.items():\n",
    "    current_columns = data.shape[1]\n",
    "    if current_columns < max_columns:\n",
    "        # Calculate how many columns to add\n",
    "        additional_columns = max_columns - current_columns\n",
    "        \n",
    "        # Create an array of NaNs to add\n",
    "        empty_columns = np.full((data.shape[0], additional_columns), np.nan)  # Use np.nan or any other placeholder\n",
    "        \n",
    "        # Concatenate the original data with the new empty columns\n",
    "        new_data = np.hstack([data, empty_columns])\n",
    "    else:\n",
    "        new_data = data\n",
    "\n",
    "    # Store the adjusted data back into the dictionary\n",
    "    adjusted_combined_data[key] = new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each array into a single vector per sample\n",
    "X = np.array([adjusted_combined_data[key].flatten() for key in adjusted_combined_data])\n",
    "y = np.array([label_dict[key] for key in adjusted_combined_data])\n",
    "\n",
    "# Now split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Identify rows with NaN values and remove them\n",
    "valid_indices = ~np.isnan(X_train).any(axis=1)\n",
    "X_train_clean = X_train[valid_indices]\n",
    "y_train_clean = y_train[valid_indices]\n",
    "\n",
    "# Perform the same operation for the test set\n",
    "valid_indices_test = ~np.isnan(X_test).any(axis=1)\n",
    "X_test_clean = X_test[valid_indices_test]\n",
    "y_test_clean = y_test[valid_indices_test]\n",
    "\n",
    "# Create and train the pipeline\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "model.fit(X_train_clean, y_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the trained pipeline model\n",
    "predictions = model.predict(X_test_clean)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test_clean, predictions)\n",
    "report = classification_report(y_test_clean, predictions, zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the pipeline with a polynomial kernel\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='poly')  # You can adjust the 'degree' parameter as needed\n",
    ")\n",
    "model.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test_clean)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test_clean, predictions)\n",
    "report = classification_report(y_test_clean, predictions, zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the pipeline with a polynomial kernel\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='rbf')  # You can adjust the 'degree' parameter as needed\n",
    ")\n",
    "model.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test_clean)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test_clean, predictions)\n",
    "report = classification_report(y_test_clean, predictions, zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the pipeline with a polynomial kernel\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='sigmoid')  # You can adjust the 'degree' parameter as needed\n",
    ")\n",
    "model.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test_clean)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test_clean, predictions)\n",
    "report = classification_report(y_test_clean, predictions, zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
